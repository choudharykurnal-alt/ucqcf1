Below is a **Phase-1 directory structure** designed **strictly for high-performance, determinism, and requirement-defined security domains**, aligned with every decision weâ€™ve locked so far.

This is **not** a generic project layout.
It encodes **architecture decisions directly into the filesystem**.

---

# UCQCF Phase-1 â€” High-Performance Directory Structure

> **Rule:** If something is in the wrong directory, it is a security bug.

---

## 1. Top-Level Layout (Phase-1 Only)

```
ucqcf/
â””â”€â”€ |
    â”œâ”€â”€ boot/
    â”œâ”€â”€ topology/
    â”œâ”€â”€ scheduler/
    â”œâ”€â”€ domains/
    â”œâ”€â”€ memory/
    â”œâ”€â”€ pipeline/
    â”œâ”€â”€ time/
    â”œâ”€â”€ failure/
    â”œâ”€â”€ observability/
    â”œâ”€â”€ hw/
    â”œâ”€â”€ arch/
    â”œâ”€â”€ runtime/
    â”œâ”€â”€ seal/
    â”œâ”€â”€ config/
    â”œâ”€â”€ include/
    â””â”€â”€ tests/
```

Each directory maps to **exactly one architectural responsibility**.

---

## 2. `boot/` â€” Deterministic Bring-Up

```
boot/
â”œâ”€â”€ early_init.c
â”œâ”€â”€ cpu_probe.c
â”œâ”€â”€ numa_probe.c
â”œâ”€â”€ cache_probe.c
â”œâ”€â”€ microcode.c
â””â”€â”€ boot_contract.h
```

**Responsibilities**

* CPU & topology discovery
* No dynamic allocation
* No policy interpretation
* Produces immutable boot facts

---

## 3. `topology/` â€” Core & Cache Geometry

```
topology/
â”œâ”€â”€ core_map.c
â”œâ”€â”€ cache_map.c
â”œâ”€â”€ numa_map.c
â”œâ”€â”€ isolation_rules.c
â””â”€â”€ topology_contract.h
```

**Why separate?**
Topology is security-critical and **must not be scheduler-dependent**.

---

## 4. `scheduler/` â€” Deterministic Secure Scheduler

```
scheduler/
â”œâ”€â”€ scheduler.c
â”œâ”€â”€ scheduler_state.c
â”œâ”€â”€ scheduler_rules.c
â”œâ”€â”€ core_affinity.c
â”œâ”€â”€ preemption.c
â””â”€â”€ scheduler_contract.h
```

**Strict rule**

* No crypto
* No memory allocation
* No failure logic

Scheduler enforces **only execution order**.

---

## 5. `domains/` â€” Requirement-Defined Security Domains

```
domains/
â”œâ”€â”€ domain.c
â”œâ”€â”€ domain_validate.c
â”œâ”€â”€ domain_graph.c
â”œâ”€â”€ domain_constraints.c
â””â”€â”€ domain_contract.h
```

**Contains**

* Domain schema
* Validation rules
* Dependency constraints

**Does NOT contain**

* Any notion of â€œdefenseâ€ or â€œuserâ€

---

## 6. `memory/` â€” High-Performance Memory Domains

```
memory/
â”œâ”€â”€ mem_domain.c
â”œâ”€â”€ mem_alloc_static.c
â”œâ”€â”€ mem_alloc_huge.c
â”œâ”€â”€ mem_wipe.c
â”œâ”€â”€ mem_barrier.c
â””â”€â”€ memory_contract.h
```

**Performance decisions live here**

* Huge pages
* NUMA locality
* Zero-copy rules

---

## 7. `pipeline/` â€” Static Execution Pipelines

```
pipeline/
â”œâ”€â”€ pipeline.c
â”œâ”€â”€ pipeline_stage.c
â”œâ”€â”€ pipeline_validate.c
â”œâ”€â”€ pipeline_graph.c
â””â”€â”€ pipeline_contract.h
```

**Rules**

* Pipelines are immutable
* No runtime branching
* Validated before sealing

---

## 8. `time/` â€” Time & Determinism Control

```
time/
â”œâ”€â”€ clock.c
â”œâ”€â”€ latency_bounds.c
â”œâ”€â”€ constant_time.c
â””â”€â”€ time_contract.h
```

**Security note**
Time handling is isolated to prevent accidental leaks.

---

## 9. `failure/` â€” Failure & Reaction Engine

```
failure/
â”œâ”€â”€ fault_detect.c
â”œâ”€â”€ reaction_map.c
â”œâ”€â”€ escalation.c
â”œâ”€â”€ zeroize.c
â””â”€â”€ failure_contract.h
```

**Important**

* Zeroization lives here, not in crypto
* No recovery logic

---

## 10. `observability/` â€” Non-Leaking Visibility

```
observability/
â”œâ”€â”€ events.c
â”œâ”€â”€ metrics.c
â”œâ”€â”€ audit.c
â””â”€â”€ observability_contract.h
```

**Guarantee**

* Aggregated only
* No per-task timing

---

## 11. `hw/` â€” Hardware Binding Layer

```
hw/
â”œâ”€â”€ cpu.c
â”œâ”€â”€ cache_ctrl.c
â”œâ”€â”€ numa_ctrl.c
â”œâ”€â”€ accelerator.c
â”œâ”€â”€ trng.c
â””â”€â”€ hw_contract.h
```

**Contains**

* Instruction fencing
* Accelerator interfaces
* TRNG hooks

---

## 12. `arch/` â€” Architecture-Specific Code

```
arch/
â”œâ”€â”€ x86_64/
â”‚   â”œâ”€â”€ fences.S
â”‚   â”œâ”€â”€ cache.S
â”‚   â””â”€â”€ arch_init.c
â”œâ”€â”€ armv8/
â”‚   â”œâ”€â”€ barriers.S
â”‚   â””â”€â”€ arch_init.c
â””â”€â”€ arch_contract.h
```

No `#ifdef` chaos elsewhere.

---

## 13. `runtime/` â€” Minimal Execution Runtime

```
runtime/
â”œâ”€â”€ entry.c
â”œâ”€â”€ context.c
â”œâ”€â”€ stack.c
â””â”€â”€ runtime_contract.h
```

**Rules**

* No allocation
* No scheduling logic
* No failure handling

---

## 14. `seal/` â€” Immutability Enforcement (Critical)

```
seal/
â”œâ”€â”€ seal.c
â”œâ”€â”€ lock.c
â”œâ”€â”€ verify.c
â””â”€â”€ seal_contract.h
```

Once sealing happens:

> **Nothing security-relevant changes.**

---

## 15. `config/` â€” Declarative Requirement Input

```
config/
â”œâ”€â”€ domain_layout.yaml
â”œâ”€â”€ pipeline_defs.yaml
â”œâ”€â”€ failure_map.yaml
â””â”€â”€ build_constraints.yaml
```

Parsed **once**, before sealing.

---

## 16. `include/` â€” Public Phase-1 Interfaces

```
include/
â”œâ”€â”€ phase1.h
â”œâ”€â”€ domain.h
â”œâ”€â”€ scheduler.h
â””â”€â”€ memory.h
```

Minimal and stable.

---

## 17. `tests/` â€” Security & Performance Tests

```
tests/
â”œâ”€â”€ invariants/
â”œâ”€â”€ stress/
â”œâ”€â”€ fault_injection/
â”œâ”€â”€ timing/
â””â”€â”€ topology/
```

No unit tests only â€” **invariant tests are mandatory**.

---

## 18. Performance-Driven Structural Rules

1. No circular dependencies
2. No cross-directory state mutation
3. One responsibility per directory
4. Hardware-adjacent code isolated
5. Validation happens before sealing

---

## 19. Why This Structure Is High-Performance

* Cache locality via responsibility isolation
* Predictable code paths
* Minimal indirection
* Compile-time specialization
* Easy formal reasoning


Let me analyze the Phase-1 flow against what we've implemented and identify any gaps or concerns.

## ğŸ” Analysis of Phase-1 Flow vs Implementation

### âœ… What We Have Correct

**Layers 0-4 are solid:**

1. **Runtime/Entry** âœ… - Conceptually sound (minimal stub needed)
2. **Boot** âœ… - Fully implemented with proper sequencing
3. **HW/Arch** âœ… - x86_64 primitives implemented
4. **Topology** âœ… - Complete with corrected validation
5. **Domains** âœ… - Validated against sealed topology

### âš ï¸ Critical Observation: HW Layer Position

**Potential Issue in Flow:**

The document shows:
```
boot/ â†’ hw/ + arch/ â†’ topology/
```

But logically, `hw/` should be **used by** boot, not come **after** boot:

```
CORRECT: runtime/ â†’ boot/ (uses hw/arch/) â†’ topology/
```

**Reasoning:**
- Boot probing **needs** hw/arch primitives (CPUID, MSR reads)
- HW layer provides the primitives boot uses
- HW is not a "step", it's an **interface layer**

**Recommendation:** HW/arch should be thought of as a **library** used by boot, not a sequential step.

---

## ğŸš¨ Implementation Gaps (Need Attention)

### Gap 1: Scheduler Implementation (NEXT CRITICAL STEP)

**Status:** âŒ Not implemented yet

**Required Files:**
```
scheduler/
â”œâ”€â”€ scheduler.c           âŒ Missing
â”œâ”€â”€ scheduler_state.c     âŒ Missing
â”œâ”€â”€ scheduler_rules.c     âŒ Missing
â”œâ”€â”€ core_affinity.c       âŒ Missing
â”œâ”€â”€ preemption.c          âŒ Missing
â””â”€â”€ scheduler_contract.h  âŒ Missing
```

**What Scheduler MUST Do:**
```c
// Consume sealed topology + sealed domains
scheduler_init(&scheduler, &boot_facts, &topology, &domain_graph);

// Produce deterministic rules
bool can_schedule_task(task_id_t task, core_id_t core);
void enforce_preemption(domain_id_t preempting, domain_id_t preempted);
```

**Critical Requirements:**
- âœ… No memory allocation
- âœ… No crypto
- âœ… No failure logic
- âœ… Purely mechanical enforcement
- âœ… Table-driven decisions only

---

### Gap 2: Memory Layer

**Status:** âŒ Not implemented

**Required:**
```
memory/
â”œâ”€â”€ mem_domain.c          âŒ Missing
â”œâ”€â”€ mem_alloc_static.c    âŒ Missing
â”œâ”€â”€ mem_alloc_huge.c      âŒ Missing
â”œâ”€â”€ mem_wipe.c            âŒ Missing
â”œâ”€â”€ mem_barrier.c         âŒ Missing
â””â”€â”€ memory_contract.h     âŒ Missing
```

**Critical Property:**
> No memory allocation after memory layer completes

**Must Provide:**
- NUMA-local allocation
- Huge page management
- Domain isolation
- Memory locking (mlockall)
- Pre-allocation of all runtime needs

---

### Gap 3: Time Layer

**Status:** âŒ Not implemented

**Required:**
```
time/
â”œâ”€â”€ clock.c               âŒ Missing
â”œâ”€â”€ latency_bounds.c      âŒ Missing
â”œâ”€â”€ constant_time.c       âŒ Missing
â””â”€â”€ time_contract.h       âŒ Missing
```

**Must Provide:**
- Monotonic clock selection
- Latency bound enforcement
- Constant-time operation verification
- Timing side-channel prevention

---

### Gap 4: Pipeline Layer

**Status:** âŒ Not implemented

**Required:**
```
pipeline/
â”œâ”€â”€ pipeline.c            âŒ Missing
â”œâ”€â”€ pipeline_stage.c      âŒ Missing
â”œâ”€â”€ pipeline_validate.c   âŒ Missing
â”œâ”€â”€ pipeline_graph.c      âŒ Missing
â””â”€â”€ pipeline_contract.h   âŒ Missing
```

**Must Validate:**
- Domain transitions are legal
- Memory handoffs are safe
- Latency bounds are met
- No cycles in pipeline graph

---

### Gap 5: Failure Layer

**Status:** âŒ Not implemented

**Required:**
```
failure/
â”œâ”€â”€ fault_detect.c        âŒ Missing
â”œâ”€â”€ reaction_map.c        âŒ Missing
â”œâ”€â”€ escalation.c          âŒ Missing
â”œâ”€â”€ zeroize.c             âŒ Missing
â””â”€â”€ failure_contract.h    âŒ Missing
```

**Critical:**
- Zeroization must be here, not in crypto
- No recovery logic (fail-stop only)
- Explicit fault â†’ reaction mapping

---

### Gap 6: Observability Layer

**Status:** âŒ Not implemented

**Required:**
```
observability/
â”œâ”€â”€ events.c              âŒ Missing
â”œâ”€â”€ metrics.c             âŒ Missing
â”œâ”€â”€ audit.c               âŒ Missing
â””â”€â”€ observability_contract.h âŒ Missing
```

**Guarantee:**
- Aggregated metrics only
- No per-task timing
- Cannot be used as side channel

---

### Gap 7: Seal Layer

**Status:** âŒ Not implemented

**Required:**
```
seal/
â”œâ”€â”€ seal.c                âŒ Missing
â”œâ”€â”€ lock.c                âŒ Missing
â”œâ”€â”€ verify.c              âŒ Missing
â””â”€â”€ seal_contract.h       âŒ Missing
```

**Must Verify:**
```c
assert(boot_sealed);
assert(topology_sealed);
assert(domains_validated);
assert(scheduler_deterministic);
assert(memory_locked);
assert(pipelines_validated);
assert(failure_defined);
assert(observability_configured);

seal_all();  // ONE-WAY TRANSITION
```

---

## ğŸ¯ Corrected Implementation Order

Based on dependencies, here's the **strict** order:

```
1. âœ… runtime/entry.c          (minimal context)
2. âœ… boot/ + arch/x86_64/     (hardware facts)
3. âœ… topology/                 (geometry + seal)
4. âœ… domains/                  (policy + validate)
5. âŒ scheduler/                (enforcement - NEXT)
6. âŒ memory/                   (allocation + lock)
7. âŒ time/                     (determinism)
8. âŒ pipeline/                 (cross-domain flow)
9. âŒ failure/                  (reaction matrix)
10. âŒ observability/           (safe visibility)
11. âŒ seal/                    (immutability)
```

---

## ğŸ”´ Critical Questions About The Flow

### Question 1: When Does HW Layer Get "Validated"?

The flow document says:
```
hw/ + arch/ â†’ topology/
```

**Problem:** HW layer doesn't produce a "sealed" artifact.

**Resolution:** HW layer is a **library**, not a step. It's validated implicitly when:
- Boot probing succeeds
- Topology uses it successfully
- All primitives work as expected

**Recommendation:** Remove HW as a distinct "step". It's infrastructure.

---

### Question 2: Memory Pre-Allocation Scope

The flow says:
> No memory allocation after this step

**Question:** What about runtime stack growth?

**Resolution Needed:**
- Pre-allocate all task stacks
- Pre-allocate all pipeline buffers
- Pre-allocate all observability buffers
- Lock all pages (mlockall)

**Must define:** Maximum memory footprint at compile time.

---

### Question 3: Pipeline Before Failure or After?

The flow shows:
```
pipeline/ â†’ failure/ â†’ observability/
```

**Question:** Does failure layer need pipeline definitions to define reactions?

**Answer:** Yes! Failure reactions depend on which pipeline stage failed.

**Implication:** Order is correct. Failure layer consumes pipeline definitions.

---

### Question 4: Seal Layer Final Verification

The document shows seal verifying everything, but:

**Question:** Who verifies the seal layer itself?

**Resolution:** Seal layer must be **trivial** and **provably correct**:
```c
// seal.c must be ~50 lines max
void seal_all(void) {
    assert(boot_facts.sealed);
    assert(topology.sealed);
    assert(domain_graph.sealed);
    // ... more checks
    
    system_state.sealed = true;
    // NO MORE CHANGES POSSIBLE
}
```

---

## âš¡ Priority Implementation Roadmap

### **Immediate Next (Week 1):**
```
scheduler/scheduler_contract.h   - Define scheduler interface
scheduler/scheduler_rules.c      - Encode domain â†’ core rules
scheduler/core_affinity.c        - Enforce affinity
scheduler/preemption.c           - Enforce preemption policy
```

**Goal:** Prove scheduler can enforce sealed domains mechanically.

---

### **Next (Week 2):**
```
memory/memory_contract.h         - Define memory interface
memory/mem_domain.c              - Domain-isolated allocation
memory/mem_alloc_static.c        - Pre-allocation logic
memory/mem_alloc_huge.c          - Huge page management
memory/mem_barrier.c             - Memory fences
```

**Goal:** Prove all memory is pre-allocated and locked.

---

### **Then (Week 3):**
```
time/time_contract.h             - Define time interface
time/clock.c                     - Monotonic clock
time/latency_bounds.c            - Bound enforcement
time/constant_time.c             - CT verification
```

**Goal:** Prove timing is deterministic.

---

### **Then (Week 4):**
```
pipeline/pipeline_contract.h     - Define pipeline interface
pipeline/pipeline.c              - Pipeline construction
pipeline/pipeline_validate.c     - Validation logic
```

**Goal:** Prove cross-domain execution is safe.

---

### **Then (Week 5):**
```
failure/failure_contract.h       - Define failure interface
failure/fault_detect.c           - Detection logic
failure/reaction_map.c           - Fault â†’ reaction
failure/zeroize.c                - Secure erasure
```

**Goal:** Prove failure handling is deterministic.

---

### **Then (Week 6):**
```
observability/observability_contract.h - Define observability
observability/events.c           - Event aggregation
observability/metrics.c          - Metric collection
observability/audit.c            - Audit logging
```

**Goal:** Prove observability doesn't leak secrets.

---

### **Finally (Week 7):**
```
seal/seal_contract.h             - Define seal interface
seal/seal.c                      - Final verification
seal/verify.c                    - State verification
seal/lock.c                      - Immutability enforcement
```

**Goal:** Prove Phase-1 is complete and immutable.

---

## ğŸ“‹ My Assessment

### âœ… What's Solid
- Boot layer is production-ready
- Topology layer is production-ready
- Domain layer is production-ready
- Corrections have been applied
- Flow logic is sound

### âš ï¸ What Needs Clarification
- HW layer position (it's infrastructure, not a step)
- Memory pre-allocation scope needs definition
- Seal layer must be provably trivial

### ğŸš€ What's Next
**Immediate:** Implement scheduler with sealed domains

**Critical Path:**
```
Scheduler â†’ Memory â†’ Time â†’ Pipeline â†’ Failure â†’ Observability â†’ Seal
```

---

You are **absolutely going in the right direction** â€” and more importantly, you are now reasoning at the *correct abstraction level* for Phase-1.

Iâ€™ll be very clear and very strict below.

---

# âœ… Verdict (Short, Direct)

**Yes â€” your Phase-1 flow, corrections, and roadmap are architecturally sound.**
**Your HW-layer correction is correct and necessary.**
**Scheduler is the correct next component to implement.**

There are **no foundational design errors** left in your Phase-1 model.

What remains are **precision tightenings**, not restructures.

---

# ğŸ”’ Confirmation of Your Critical Correction

You identified the single real conceptual bug correctly:

> **HW/arch is not a phase â€” it is infrastructure.**

### Correct Mental Model (LOCK THIS)

```
runtime/entry
   â†“
boot/        (USES hw/arch)
   â†“
topology/    (USES hw/arch)
   â†“
domains/
   â†“
scheduler/
   â†“
...
```

**HW/arch never â€œrunsâ€**
It:

* exports primitives
* never owns state
* never seals
* never enforces policy

Treating it as a step would have been a category error.

âœ… **You fixed it.**

---

# âœ… Layer-by-Layer Reality Check

Iâ€™ll go through your analysis and either **confirm** or **correct**.

---

## Layers 0â€“4 (Runtime â†’ Domains)

### Status: **PRODUCTION-GRADE**

* Runtime entry is minimal and correct
* Boot is deterministic and sealed
* Topology validation is real, not symbolic
* Domain validation against sealed topology is correct

ğŸ” These layers already form a **hardware â†’ geometry â†’ trust proof chain**

You did not miss anything here.

---

## Scheduler Layer (NEXT STEP)

Your definition is **exactly correct**:

> â€œPurely mechanical enforcementâ€

### Scheduler MUST be:

* Table-driven
* Branch-minimal
* Allocation-free
* Immutable after init
* Provably incapable of violating domains

### Scheduler MUST NOT:

* Inspect memory
* Inspect crypto
* Handle faults
* Parse config
* Query topology dynamically

Your proposed interface is correct:

```c
bool can_schedule_task(task_id_t, core_id_t);
void enforce_preemption(domain_id_t, domain_id_t);
```

âœ… **Proceed with scheduler next.**

---

## Memory Layer â€” Your Clarification Is Required (And You Noticed It)

You correctly asked:

> â€œWhat about runtime stack growth?â€

### Correct Resolution (AUTHORITATIVE)

**ALL memory must be pre-allocated before sealing**, including:

* All task stacks (max depth)
* All pipeline buffers
* All observability buffers
* All scheduler metadata
* All failure bookkeeping

After memory init:

```
malloc = forbidden
mmap   = forbidden
sbrk   = forbidden
```

Only:

* stack pointer movement inside pre-mapped regions
* fixed-address access

You are correct:
ğŸ‘‰ **Maximum memory footprint must be known at build/config time.**

---

## Pipeline â†’ Failure Ordering

Your reasoning is correct.

Failure **must consume pipeline definitions**, because reactions depend on:

* stage
* domain
* memory involved
* timing state

âœ… Order is correct.

---

## Seal Layer â€” Your Triviality Requirement Is CORRECT

This is important:

> **Seal must be boring.**

You are right to demand:

* ~50 LOC
* no branching logic
* no mutation beyond the final lock

Seal is not intelligence â€” it is a **one-way latch**.

Anything clever here would be a red flag.

---

# âš ï¸ One Small Tightening (Not a Correction)

### Add This Explicit Rule

**Scheduler must not observe time.**

Time logic lives strictly in `time/`.

Scheduler enforces *order*, not *duration*.

This preserves:

* constant-time execution
* side-channel isolation
* formal verifiability

Thatâ€™s the only thing Iâ€™d explicitly lock.

---

# ğŸ§­ Final Corrected Phase-1 Flow (Canonical)

```
runtime/entry
   â†“
boot/          (uses hw/arch)
   â†“
topology/      (uses hw/arch)
   â†“
domains/
   â†“
scheduler/     â† NEXT
   â†“
memory/
   â†“
time/
   â†“
pipeline/
   â†“
failure/
   â†“
observability/
   â†“
seal/
```

This flow is **defensible**, **provable**, and **performance-optimal**.

---

